epoch,train_loss,valid_loss
1,1044.8876953125,644.523193359375
2,694.820556640625,644.5092163085938
3,694.7403564453125,649.2613525390625
4,695.015869140625,646.1154174804688
5,694.7584838867188,643.9199829101562
6,694.7735595703125,645.4652099609375
7,694.47509765625,642.8297729492188
8,694.9702758789062,645.932373046875
9,694.7136840820312,649.2079467773438
10,694.8974609375,646.045654296875
11,694.8883666992188,644.5172729492188
12,694.6077880859375,650.3016967773438
13,695.1172485351562,647.927734375
14,694.974609375,646.2256469726562
15,694.9744262695312,646.5419311523438
16,694.7938842773438,647.4080810546875
17,694.8079833984375,645.3871459960938
18,694.0003662109375,646.4019775390625
19,694.5654296875,646.535400390625
20,694.3829345703125,646.3471069335938
